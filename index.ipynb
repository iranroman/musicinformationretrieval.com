{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/stevetjoa/stanford-mir\"><img style=\"position: absolute; top: 0; right: 0; border: 0;\" src=\"https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67\" alt=\"Fork me on GitHub\" data-canonical-src=\"https://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Music Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The 2017 Summer Workshop on MIR at CCRMA, Stanford](https://ccrma.stanford.edu/workshops/music-information-retrieval-2017), is all sold out. Sorry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   [**About This Site**](about.html) ([ipynb](about.ipynb)) Start here!\n",
    "1.   [What is MIR?](why_mir.html) ([ipynb](why_mir.ipynb))\n",
    "1.   [Python Basics](python_basics.html) ([ipynb](python_basics.ipynb))\n",
    "1.   [Jupyter Basics](get_good_at_ipython.html) ([ipynb](get_good_at_ipython.ipynb))\n",
    "1.   [Jupyter Audio Basics](ipython_audio.html) ([ipynb](ipython_audio.ipynb))\n",
    "1.   [NumPy and SciPy Basics](numpy_basics.html) ([ipynb](numpy_basics.ipynb))\n",
    "1.   [Alphabetical Index of Terms](alphabetical_index.html) ([ipynb](alphabetical_index.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [Sheet Music Representations](sheet_music_representations.html) ([ipynb](sheet_music_representations.ipynb))\n",
    "1.  [Symbolic Representations](symbolic_representations.html) ([ipynb](symbolic_representations.ipynb))\n",
    "1.  [Audio Representation](audio_representation.html) ([ipynb](audio_representation.ipynb))\n",
    "1.  [Tuning Systems](tuning_systems.html) ([ipynb](tuning_systems.ipynb))\n",
    "1.  [Understanding Audio Features through Sonification](feature_sonification.html) ([ipynb](feature_sonification.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Analysis and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [Basic Feature Extraction](basic_feature_extraction.html) ([ipynb](basic_feature_extraction.ipynb))\n",
    "1.  [Segmentation](segmentation.html) ([ipynb](segmentation.ipynb))\n",
    "1.  [Energy and RMSE](energy.html) ([ipynb](energy.ipynb))\n",
    "1.  [Zero Crossing Rate](zcr.html) ([ipynb](zcr.ipynb))\n",
    "1.  [Fourier Transform](fourier_transform.html) ([ipynb](fourier_transform.ipynb))\n",
    "1.  [Short-time Fourier Transform and Spectrogram](stft.html) ([ipynb](stft.ipynb))\n",
    "1.  [Constant-Q Transform and Chroma](chroma.html) ([ipynb](chroma.ipynb))\n",
    "1.  [Magnitude Scaling](magnitude_scaling.html) ([ipynb](magnitude_scaling.ipynb))\n",
    "1.  [Spectral Features](spectral_features.html) ([ipynb](spectral_features.ipynb))\n",
    "1.  [Autocorrelation](autocorrelation.html) ([ipynb](autocorrelation.ipynb))\n",
    "1.  [Pitch Transcription Exercise](pitch_transcription_exercise.html) ([ipynb](pitch_transcription_exercise.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhythm, Tempo, and Beat Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [Novelty Functions](novelty_functions.html) ([ipynb](novelty_functions.ipynb))\n",
    "1.  [Peak Picking](peak_picking.html) ([ipynb](peak_picking.ipynb))\n",
    "1.  [Onset Detection](onset_detection.html) ([ipynb](onset_detection.ipynb))\n",
    "1.  [Onset-based Segmentation with Backtracking](onset_segmentation.html) ([ipynb](onset_segmentation.ipynb))\n",
    "1.  [Tempo Estimation](tempo_estimation.html) ([ipynb](tempo_estimation.ipynb))\n",
    "1.  [Beat Tracking](beat_tracking.html) ([ipynb](beat_tracking.ipynb))\n",
    "1.  [Drum Transcription using ADTLib](adtlib.html) ([ipynb](adtlib.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [K-Nearest Neighbor Classification](knn.html) ([ipynb](knn.ipynb))\n",
    "1.  [Cross Validation](cross_validation.html) ([ipynb](cross_validation.ipynb))\n",
    "1.  [Exercise: K-Nearest Neighbor Instrument Classification](knn_instrument_classification.html) ([ipynb](knn_instrument_classification.ipynb))\n",
    "1.  [K-Means Clustering](kmeans.html) ([ipynb](kmeans.ipynb))\n",
    "1.  [Exercise: Unsupervised Instrument Classification using K-Means](kmeans_instrument_classification.html) ([ipynb](kmeans_instrument_classification.ipynb))\n",
    "1.  [Neural Networks](neural_networks.html) ([ipynb](neural_networks.ipynb))\n",
    "1.  [Evaluation](evaluation.html) ([ipynb](evaluation.ipynb))\n",
    "1.  [Genre Recognition](genre_recognition.html) ([ipynb](genre_recognition.ipynb))\n",
    "1.  [Exercise: Genre Recognition](exercise_genre_recognition.html) ([ipynb](exercise_genre_recognition.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Dynamic Programming](dp.html) ([ipynb](dp.ipynb))\n",
    "1. [Longest Common Subsequence](lcs.html) ([ipynb](lcs.ipynb))\n",
    "1. [Dynamic Time Warping](dtw.html) ([ipynb](dtw.ipynb))\n",
    "1. [Dynamic Time Warping Example](dtw_example.html) ([ipynb](dtw_example.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Structure Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [Mel-Frequency Cepstral Coefficients](mfcc.html) ([ipynb](mfcc.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Audio Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Locality Sensitive Hashing](lsh_fingerprinting.html) ([ipynb](lsh_fingerprinting.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musically Informed Audio Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [Principal Component Analysis](pca.html) ([ipynb](pca.ipynb))\n",
    "1.  [Nonnegative Matrix Factorization](nmf.html) ([ipynb](nmf.ipynb))\n",
    "1.  [Harmonic-Percussive Source Separation](hpss.html) ([ipynb](hpss.ipynb))\n",
    "1.  [Exercise: Source Separation using NMF](nmf_source_separation.html) ([ipynb](nmf_source_separation.ipynb))\n",
    "1.  Classification of Separated Signals\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
